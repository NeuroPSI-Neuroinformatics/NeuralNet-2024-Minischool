{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4374a2",
   "metadata": {},
   "source": [
    "# Case study for data reuse with EBRAINS Knowledge Graph: A step-by-step explanation \n",
    "\n",
    "Alix E.Bonard, Laura Morel and Peyman Najafi\n",
    "\n",
    "Paris-Saclay Institute of Neuroscience, CNRS, Université Paris-Saclay, France.\n",
    "\n",
    "November 2024, NeuralNet2024 - Minischool - Hands-on case studies for data reuse \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f0625",
   "metadata": {},
   "source": [
    "In this notebook we will look more closely at the EBRAINS dataset \"[Excitability profile of CA1 pyramidal neurons in APPPS1 Alzheimer disease mice and control littermates (v1)](https://search.kg.ebrains.eu/#bd5f91ff-e829-4b85-92eb-fc56991541f1)\", contributed by Ana Rita Salgueiro-Pereira and Hélène Marie from the Université Côte d’Azur in Valbonne, France.\n",
    "\n",
    "As we can see from the dataset description,\n",
    "\n",
    "<i>This dataset provides an analysis of the intrinsic electrophysiological properties of CA1 excitatory hippocampal\n",
    "neurons in a mouse model of Alzheimer’s Disease (AD) at two age points: a presymptomatic age (3-4\n",
    "months) and a symptomatic age: (9-10 months).</i>\n",
    "More information is available in the [Data Descriptor](https://search.kg.ebrains.eu/instances/bd5f91ff-e829-4b85-92eb-fc56991541f1).\n",
    "\n",
    "This dataset forms part of the results reported in Vitale, P., Salgueiro-Pereira, A. R., Lupascu, C. A., Willem, M., Migliore, R., Migliore, M., & Marie, H.(2021) Analysis of Age-Dependent Alterations in Excitability Properties of CA1 Pyramidal Neurons in an APPPS1 Model of Alzheimer’s Disease. *Frontiers in Aging Neuroscience* **13** https://doi.org/10.3389/fnagi.2021.668948\n",
    "\n",
    "This notebook was modified from [Studies of data reuse: Excitability profile of CA1 pyramidal neurons in APPPS1 Alzheimer disease mice and control littermates](https://github.com/NeuroPSI-Neuroinformatics/case-studies-for-data-reuse/blob/main/10.25493-YJFW-HPY/SalgueiroPereiraMarie2020.ipynb) by Isaure Botherel and Andrew P.Davison. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1ff01",
   "metadata": {},
   "source": [
    "**In this notebook we will demonstrate how to access, to explore and to reuse the data from this study using fairgraph and neo packages. We will also visualize the data with matplotlib by focusing on providing detailed information for data reuse.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f2e75",
   "metadata": {},
   "source": [
    "### Finding a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef186419",
   "metadata": {},
   "source": [
    "This section aims to teach users how to programatically or manually find and retrieve datasets with specific metadata on the EBRAINS Knowledge Graph (KG). The following tools will be used:\n",
    "- the python library fairgraph\n",
    "- the EBRAINS website KGSearch\n",
    "- the EBRAINS website KGQueryBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f120138",
   "metadata": {},
   "source": [
    "#### Using [KGSearch](https://search.kg.ebrains.eu/?category=Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f83130",
   "metadata": {},
   "source": [
    "[KGSearch](https://search.kg.ebrains.eu/?category=Dataset) is a quick and easy way to browse EBRAINS datasets. Once a dataset is selected, users can use the Python library [fairgraph](https://github.com/HumanBrainProject/fairgraph) to download the dataset and/or see its metadata using its client. Since we are already working in a Jupyter lab linked to our EBRAINS account, we simply need to create a client object **KGClient** to be able to retrieve metadata on the KG. For more instructions on how to use fairgraph in other environments, please refer to the github page linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be87896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairgraph import KGClient\n",
    "kg_client = KGClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c81e9f",
   "metadata": {},
   "source": [
    "**EXERCISE**\\\n",
    "To familiarize ourselves with KGSearch, let us try to find a dataset with the following characteristics:\n",
    "- Technique used is **whole-cell patch clamp**\n",
    "- Cell type is **CA1 pyramidal neurons**\n",
    "- Sujects are **model mice for Alzheimer's disease**\n",
    "\n",
    "Those parameters should lead you to [this dataset](https://search.kg.ebrains.eu/instances/bd5f91ff-e829-4b85-92eb-fc56991541f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbe662",
   "metadata": {},
   "source": [
    "The KG uses the [openMinds](https://github.com/openMetadataInitiative/openMINDS) framework for metadata. In this framework, a **Dataset** instance is linked to one or more **DatasetVersion** instances with unique DOIs. *fairgraph* allows us to directly download the dataset using its DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21505a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairgraph.openminds.core as omcore\n",
    "import os \n",
    "import zipfile\n",
    "\n",
    "dataset_version_doi = \"10.25493/YJFW-HPY\"\n",
    "\n",
    "dataset_versions = omcore.DatasetVersion.list(\n",
    "    kg_client, \n",
    "    digital_identifier__identifier=dataset_version_doi,\n",
    "    follow_links={\"repository\": {\"files\": {}}},\n",
    "    scope=\"any\"\n",
    ")\n",
    "\n",
    "dataset_version = dataset_versions[0]\n",
    "\n",
    "if not os.path.exists(\"downloads\"):  # only download the dataset if it hasn't been downloaded previously\n",
    "    dataset_path = dataset_version.download(\"downloads\", kg_client, accept_terms_of_use=True)[0]\n",
    "else:\n",
    "    dataset_path = \"downloads/ext-d000001_ADNeuronModel_pub\"\n",
    "with zipfile.ZipFile(dataset_path, \"r\") as z:\n",
    "    z.extractall(\"downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26f400",
   "metadata": {},
   "source": [
    "#### More sophisticated queries with [KGQueryBuilder](https://query.kg.ebrains.eu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a3804",
   "metadata": {},
   "source": [
    "To query the KG programatically, instead of using the KGSearch website, we can use the KGQuery object from fairgraph. However, the query must be serializable in JSON-LD to be valid. The [KGQueryBuilder](https://query.kg.ebrains.eu) website aims to help users write queries for the EBRAINS Knowledge Graph.\n",
    "Using this tool, try and find the dataset previously found. [A tutorial](https://docs.kg.ebrains.eu/9b511d36d7608eafc94ea43c918f16b6/tutorials.html) is available to learn how to use this tool. Once you think you have the correct query, paste it below to check if it is correct.\n",
    "**Note:** if your query contains the words `true` or `false` without quotes, remember to capitalize the first letter to make it interpretable by Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b2dfb",
   "metadata": {},
   "source": [
    "**EXERCISE: Build a query with KG Query builder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "query = {\n",
    "    # PASTE YOUR QUERY HERE\n",
    "}\n",
    "results = kg_client.query(query)\n",
    "pprint(results.data, width=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e49509",
   "metadata": {},
   "source": [
    "## Structure of Folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e7f3c",
   "metadata": {},
   "source": [
    "The data are organized into four folders, \"APPPS1_mouse_model_3-4_months\", \"control_3-4_months\", \"APPPS1_mouse_model_9-10_months\", \"control_9-10_months\", each of which contains a number of files with the extension \".abf\".\n",
    "\n",
    "It should be noted that the dataset does not contain the data for mice at age 1 month that are shown in the associated paper (Vitale et al., 2021).\n",
    "\n",
    "We know from the dataset metadata that these are electrophysiology data, and more specifically that they were obtained with the whole cell patch clamp technique in current clamp mode. We will therefore use the [Neo library](https://neo.readthedocs.io/) to read the data files, since it is able to read data from a large number of electrophysiology file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.listdir()[1]) # gets the path of the second element in the working directory. In this case it is \"downloads\".  \n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_folders_list = []\n",
    "sub_folders_list = []\n",
    "files_list = []\n",
    "for path_folders, sub_folders, files in os.walk(data_folder):\n",
    "    path_folders_list.append(path_folders)\n",
    "    sub_folders_list.append(sub_folders)\n",
    "    files_list.append(files)\n",
    "\n",
    "print(f\"The dataset contains {len(path_folders_list[1:])} folders corresponding to the experimental groups\")\n",
    "for i in range (1, (len(path_folders_list))):\n",
    "    print(f\"The folfer {path_folders_list[i]} contains {len(files_list[i])} files with the extension .abf ({files_list[i]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904b7ca-ed8a-4eca-9885-7c5f659debee",
   "metadata": {},
   "source": [
    "## Exploring Neo package: FAIR and flexible tool to analyze/visualize your data \n",
    "FAIR principle related to Neo:\\\n",
    "I1: (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.\\\n",
    "I3: (meta)data include qualified references to other (meta)data\\\n",
    "R1.3: (meta)data meet domain-relevant community standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febe07c3-48cf-476f-afe2-d8048145d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from neo import get_io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ce055-ae45-4fe1-b7c2-c9b46548236d",
   "metadata": {},
   "source": [
    "Neo loads data into a hierarchical structure: Blocks contain Segments, which contain the actual data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbded7f6",
   "metadata": {},
   "source": [
    "![title](Neo_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cbf1ba",
   "metadata": {},
   "source": [
    "Let us look at the structure of the first three files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160df841-fad2-42e6-8d69-8d847cc107ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxonIO: downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf\n",
      "nb_block: 1\n",
      "nb_segment:  [13]\n",
      "signal_streams: [Signals (chans: 1)]\n",
      "signal_channels: [IN0]\n",
      "spike_channels: []\n",
      "event_channels: [Tag]\n",
      "\n",
      "AxonIO: downloads/APPPS1_mouse_model_3-4_months/191129002_S23.abf\n",
      "nb_block: 1\n",
      "nb_segment:  [13]\n",
      "signal_streams: [Signals (chans: 1)]\n",
      "signal_channels: [IN0]\n",
      "spike_channels: []\n",
      "event_channels: [Tag]\n",
      "\n",
      "AxonIO: downloads/APPPS1_mouse_model_3-4_months/191129003_S23.abf\n",
      "nb_block: 1\n",
      "nb_segment:  [13]\n",
      "signal_streams: [Signals (chans: 1)]\n",
      "signal_channels: [IN0]\n",
      "spike_channels: []\n",
      "event_channels: [Tag]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_path in glob(\"downloads/*/*.abf\")[:3]:\n",
    "    io = get_io(file_path)\n",
    "    print(io)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a212032",
   "metadata": {},
   "source": [
    "**EXERCISE: Knowing the structure of Neo object, retrieve the signal ?**\n",
    "\n",
    "Hint:\n",
    "\n",
    "block = get_io(\"downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf\").read(lazy=True) #using read(lazy=True) implies to use .load() to retrieve signals\\\n",
    "...\n",
    "\n",
    "--\\\n",
    "Output:\n",
    "\n",
    "AnalogSignal with 1 channels of length 50000; units mV; datatype float32\\\n",
    "name: 'Signals'\\\n",
    "annotations: {'stream_id': '0'}\\\n",
    "sampling rate: 10000.0 Hz\\\n",
    "time: 0.020999999999999998 s to 5.021 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78126230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution \n",
    "data = get_io(\"downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf\").read(lazy=True)\n",
    "example_signal = data[0].segments[0].analogsignals[0].load()\n",
    "example_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c4df7",
   "metadata": {},
   "source": [
    "**EXERCISE: Explore the proprieties of the object in order to obtain the raw data, the time (with and without units), the units and the sampling rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed843b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "print(f\"Raw signal:  {example_signal.magnitude.flatten()}\")\n",
    "print(f\"time with unit:  {example_signal.times}\")\n",
    "print(f\"time without unit:  {example_signal.times.magnitude}\")\n",
    "print(f\"sampling rate:  {example_signal.sampling_rate}\")\n",
    "print(f\"sampling rate without unit:  {example_signal.sampling_rate.magnitude}\")\n",
    "print(f\"time unit:  {example_signal.times.dimensionality}\")\n",
    "print(f\"signal unit:  {example_signal.units.dimensionality}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca5252-cbf7-4778-a630-276318f0124e",
   "metadata": {},
   "source": [
    "These all have a consistent structure: they're in Axon format, contain a single block containing 13 segments, and each segment contains a single recorded signal containing a single channel. \n",
    "We know from the associated paper that current pulses of increasing intensity were injected into the neurons, in steps of 50 pA from -200 to 400 pA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e587a5ef-c488-4143-9f29-3bd9c6d44a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-200 -150 -100  -50    0   50  100  150  200  250  300  350  400]\n",
      "Number of current pulses: 13\n"
     ]
    }
   ],
   "source": [
    "current_pulse_amplitudes = np.arange(-200, 401, 50)  # we set the upper limit above 400, so that the final value is 400\n",
    "print(current_pulse_amplitudes)\n",
    "print(f\"Number of current pulses: {len(current_pulse_amplitudes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b2cce-75db-46cf-927b-07f70464190a",
   "metadata": {},
   "source": [
    "Now let's plot the data from one of the files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6d014",
   "metadata": {},
   "source": [
    "**EXERCISE: Plot the membrane potential(signal) over the time for all segments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(file_path):\n",
    "    data = get_io(file_path).read(lazy=True)\n",
    "    for segment in data[0].segments:\n",
    "        signal = segment.analogsignals[0].load()\n",
    "        plt.plot(signal.times, signal)\n",
    "    plt.xlabel(f\"Time ({signal.times.units.dimensionality})\")\n",
    "    plt.ylabel(f\"Membrane potential ({signal.units.dimensionality})\")\n",
    "\n",
    "plot_data(\"downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351e0b8",
   "metadata": {},
   "source": [
    "![title](Fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45835752-309b-432b-9cc9-e5b46591ab81",
   "metadata": {},
   "source": [
    "**EXERCISE: To get a closer look at the signals, (1) shift the time axis to be relative to the start time of each signal, and (2) plot only the 500 ms around the current injection. Adjust the code used above to do so.**\n",
    "\n",
    "HINT: signal.times - signal.t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18274d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "def plot_data_zoom(file_path):\n",
    "    data = get_io(file_path).read(lazy=True)\n",
    "    for segment in data[0].segments:\n",
    "        signal = segment.analogsignals[0].load()\n",
    "        plt.plot(signal.times - signal.t_start, signal)\n",
    "    plt.xlim(0.05, 0.55)\n",
    "    plt.xlabel(f\"Time ({signal.times.units.dimensionality})\")\n",
    "    plt.ylabel(f\"Membrane potential ({signal.units.dimensionality})\")\n",
    "\n",
    "plot_data_zoom(\"downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56b2e9",
   "metadata": {},
   "source": [
    "![title](Fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574817c2",
   "metadata": {},
   "source": [
    "**EXERCISE: Restrict the signal to 1 second? to 0.6 second?**\n",
    "\n",
    "Hint: np.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_vs(file_path, value_second):\n",
    "    data = get_io(file_path).read(lazy=True)\n",
    "    for segment in data[0].segments:\n",
    "        signal = segment.analogsignals[0].load()\n",
    "        indices_vs = np.where((signal.times - signal.t_start) <= value_second)[0]\n",
    "        plt.plot(signal.times[indices_vs]-signal.t_start, signal.magnitude[indices_vs])\n",
    "    \n",
    "    plt.xlabel(f\"Time ({signal.times.units.dimensionality})\")\n",
    "    plt.ylabel(f\"Membrane potential ({signal.units.dimensionality})\")\n",
    "\n",
    "plot_data_vs(\"downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf\", 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfba15",
   "metadata": {},
   "source": [
    "### Data reuse with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f3eb4",
   "metadata": {},
   "source": [
    "**EXERCISE: Complete the code below in order to plot the membrane potential over the current amplitudes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e62a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_membrane_potential = []\n",
    "value_second = 0.6\n",
    "\n",
    "data = get_io('downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf').read(lazy=True)\n",
    "for segment in data[0].segments:\n",
    "    signal = segment.analogsignals[0].load()\n",
    "    indices_1s = np.where((signal.times - signal.t_start) <= value_second)[0]\n",
    "\n",
    "    mean_membrane_potential.append(np.mean(signal.magnitude[indices_1s]))\n",
    "    \n",
    "colors = plt.cm.tab20(np.linspace(0, 1, 13))\n",
    "plt.scatter(current_pulse_amplitudes,mean_membrane_potential, color= colors, zorder= 2)\n",
    "plt.plot(current_pulse_amplitudes,mean_membrane_potential,'-', color = 'k', alpha = 0.5, zorder=1)\n",
    "plt.xlabel(f\"Currents (pA)\", size = 15)\n",
    "plt.ylabel(f\"Mean Membrane potential ({signal.units.dimensionality})\", size = 15)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xlim(-250,450)\n",
    "ax.set_xticks([-200,-100,0,100,200,300,400,450])\n",
    "ax.set_xticklabels(['-200','-100','0','100','200','300','400', ' '], size = 12)\n",
    "ax.tick_params(axis='x', which='major', size=5) \n",
    "ax.set_xticks([-250,-150,50,-50,150,250,350], minor=True) \n",
    "ax.tick_params(axis='x', which='minor', size=3) \n",
    "\n",
    "ax.set_ylim(-85,-40)\n",
    "ax.set_yticks([-80,-70,-60,-50,-40])\n",
    "ax.set_yticklabels(['-80','-70','-60','-50','-40'], size = 12)\n",
    "ax.tick_params(axis='y', which='major', size=5) \n",
    "ax.set_yticks([-85,-75,-65,-55,-45], minor=True) \n",
    "ax.tick_params(axis='y', which='minor', size=3) \n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06fc5d",
   "metadata": {},
   "source": [
    "**EXERCISE: Reproduce this figure**\n",
    "\n",
    "HINT:\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "for i in range(len(current_pulse_amplitudes)):\n",
    "    plt.annotate(f'{annotation_points[i]}', \n",
    "                 (current_pulse_amplitudes[i], mean_membrane_potential[i]),        \n",
    "                 textcoords=\"offset points\", \n",
    "                 xytext=(5,-10),       \n",
    "                 ha='left')        \n",
    "\n",
    "ax = gca()\n",
    "\n",
    "ax.set_xlim(-250,450)\n",
    "ax.set_xticks([-200,-100,0,100,200,300,400,450])\n",
    "ax.set_xticklabels(['-200','-100','0','100','200','300','400', ' '], size = 12)\n",
    "ax.tick_params(axis='...', which='...', size=5) \n",
    "ax.set_xticks([-250,-150,50,-50,150,250,350], minor=True) \n",
    "ax.tick_params(axis='...', which='...', size=3) \n",
    "\n",
    "ax.set_ylim(-85,-40)\n",
    "ax.set_yticks([-80,-70,-60,-50,-40])\n",
    "ax.set_yticklabels(['-80','-70','-60','-50','-40'], size = 12)\n",
    "ax.set_yticks([-85,-75,-65,-55,-45], minor=True) \n",
    "ax.yaxis.set_minor_locator(...(1))   \n",
    "ax.yaxis.set_major_locator(...(5))   \n",
    "ax.tick_params(axis='...', which='minor', size=3) \n",
    "ax.tick_params(axis='...', which='major', size=5) \n",
    "\n",
    "ax.spines['...'].set_visible(False)\n",
    "ax.spines['...'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e44fff",
   "metadata": {},
   "source": [
    "![title](Figmatplotlib.png) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762be392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "\n",
    "mean_membrane_potential = []\n",
    "value_second = 0.6\n",
    "\n",
    "data = get_io('downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf').read(lazy=True)\n",
    "for segment in data[0].segments:\n",
    "    signal = segment.analogsignals[0].load()\n",
    "    indices_1s = np.where((signal.times - signal.t_start) <= value_second)[0]\n",
    "\n",
    "    mean_membrane_potential.append(np.mean(signal.magnitude[indices_1s]))\n",
    "\n",
    "# Plot & layout  \n",
    "# \n",
    "# Main Graph  \n",
    "colors = plt.cm.tab20(np.linspace(0, 1, 13))\n",
    "plt.scatter(current_pulse_amplitudes,mean_membrane_potential, color= colors, zorder= 2)\n",
    "plt.plot(current_pulse_amplitudes,mean_membrane_potential,'-', color = 'k', alpha = 0.5, zorder=1)\n",
    "plt.xlabel(f\"Currents (pA)\", size = 15)\n",
    "plt.ylabel(f\"Mean Membrane potential ({signal.units.dimensionality})\", size = 15)\n",
    "\n",
    "# Graph Annotations\n",
    "annotation_points = ['point1','point2','point3','point4',' ',' ',' ',' ',' ',' ',' ','point12','point13']\n",
    "for i in range(len(current_pulse_amplitudes)):\n",
    "    plt.annotate(f'{annotation_points[i]}', \n",
    "                 (current_pulse_amplitudes[i], mean_membrane_potential[i]),        \n",
    "                 textcoords=\"offset points\", \n",
    "                 xytext=(5,-10),       \n",
    "                 ha='left')        \n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xlim(-250,450)\n",
    "ax.set_xticks([-200,-100,0,100,200,300,400,450])\n",
    "ax.set_xticklabels(['-200','-100','0','100','200','300','400', ' '], size = 12)\n",
    "ax.tick_params(axis='x', which='major', size=5) \n",
    "ax.set_xticks([-250,-150,50,-50,150,250,350], minor=True) \n",
    "ax.tick_params(axis='x', which='minor', size=3) \n",
    "\n",
    "ax.set_ylim(-85,-40)\n",
    "ax.set_yticks([-80,-70,-60,-50,-40])\n",
    "ax.set_yticklabels(['-80','-70','-60','-50','-40'], size = 12)\n",
    "ax.set_yticks([-85,-75,-65,-55,-45], minor=True) \n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))   \n",
    "ax.yaxis.set_major_locator(MultipleLocator(5))   \n",
    "ax.tick_params(axis='y', which='minor', size=3) \n",
    "ax.tick_params(axis='y', which='major', size=5) \n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a2530f",
   "metadata": {},
   "source": [
    "**EXERCISE: Create subplots next to the points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7110646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "mean_membrane_potential = []\n",
    "value_second = 0.6\n",
    "\n",
    "data = get_io('downloads/APPPS1_mouse_model_3-4_months/191129000_S23.abf').read(lazy=True)\n",
    "for segment in data[0].segments:\n",
    "    signal = segment.analogsignals[0].load()\n",
    "    indices_1s = np.where((signal.times - signal.t_start) <= value_second)[0]\n",
    "\n",
    "    mean_membrane_potential.append(np.mean(signal.magnitude[indices_1s]))\n",
    "\n",
    "# Plot & layout  \n",
    "# \n",
    "fig, ax = plt.subplots(figsize=(18, 12))  \n",
    "\n",
    "# Main Graph  \n",
    "colors = plt.cm.tab20(np.linspace(0, 1, 13))\n",
    "plt.scatter(current_pulse_amplitudes,mean_membrane_potential, color= colors, zorder= 2)\n",
    "plt.plot(current_pulse_amplitudes,mean_membrane_potential,'-', color = 'k', alpha = 0.5, zorder=1)\n",
    "plt.xlabel(f\"Currents (pA)\", size = 15)\n",
    "plt.ylabel(f\"Mean Membrane potential ({signal.units.dimensionality})\", size = 15)\n",
    "\n",
    "# Graph Annotations\n",
    "annotation_points = ['point1','point2','point3','point4',' ',' ',' ',' ',' ',' ',' ','point12','point13']\n",
    "for i in range(len(current_pulse_amplitudes)):\n",
    "    plt.annotate(f'{annotation_points[i]}', \n",
    "                 (current_pulse_amplitudes[i], mean_membrane_potential[i]),        \n",
    "                 textcoords=\"offset points\", \n",
    "                 xytext=(-15,2),       \n",
    "                 ha='right',\n",
    "                 size=15)        \n",
    "\n",
    "# Subplots  \n",
    "for i, segment in enumerate(data[0].segments):\n",
    "    signal = segment.analogsignals[0].load()\n",
    "    indices_vs = np.where((signal.times - signal.t_start) <= value_second)[0]\n",
    "\n",
    "    signal_vs = signal.magnitude[indices_vs]\n",
    "    time_vs = signal.times[indices_vs]\n",
    "\n",
    "    # creates boxes next to each point\n",
    "    inset = inset_axes(ax,\n",
    "                       width=\"200%\", height=\"100%\",\n",
    "                       loc=\"...\",\n",
    "                       bbox_to_anchor=(current_pulse_amplitudes[i], mean_membrane_potential[i], 20, 3),  # Anchor the box\n",
    "                       bbox_transform=ax.transData, \n",
    "                       borderpad=5)\n",
    "    \n",
    "    # inserts plots in boxes\n",
    "    inset.plot(...,  color=colors[i])\n",
    "    \n",
    "    # Remove spines of all boxes\n",
    "    for spine in inset.spines.values():\n",
    "        spine.set...\n",
    "    \n",
    "    # Remove ticks for all boxes\n",
    "    inset.set_xticks([])\n",
    "\n",
    "# Move the main axes\n",
    "ax.spines['bottom']...(('data',-87))\n",
    "ax.spines['left']....(('data',-250))\n",
    "\n",
    "#\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlim(-250,450)\n",
    "ax.set_xticks([-200,-100,0,100,200,300,400,450])\n",
    "ax.set_xticklabels(['-200','-100','0','100','200','300','400', ' '], size = 12)\n",
    "ax.tick_params(axis='x', which='major', size=7) \n",
    "ax.set_xticks([-250,-150,50,-50,150,250,350], minor=True) \n",
    "ax.tick_params(axis='x', which='minor', size=5) \n",
    "\n",
    "ax.set_ylim(-87,-40)\n",
    "ax.set_yticks([-80,-70,-60,-50,-40])\n",
    "ax.set_yticklabels(['-80','-70','-60','-50','-40'], size = 12)\n",
    "ax.tick_params(axis='y', which='major', size=7) \n",
    "ax.set_yticks([-85,-75,-65,-55,-45], minor=True) \n",
    "ax.tick_params(axis='y', which='minor', size=5) \n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))   \n",
    "ax.yaxis.set_major_locator(MultipleLocator(5))   \n",
    "\n",
    "# Comments: don't forget to put the legend with plt.legend() : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c382000",
   "metadata": {},
   "source": [
    "### Creating a Neo object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c96bda",
   "metadata": {},
   "source": [
    "For this part, we want to create an Neo object from hypothetical data. These data can be find in the Minischool_NeuralNet2024_data_example.xlsx file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965124e",
   "metadata": {},
   "source": [
    "We use pandas package to acces and visualize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db15966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_data = pd.read_excel(\"Minischool_NeuralNet2024_data_example.xlsx\")\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5cb324",
   "metadata": {},
   "source": [
    "To do so, we create a function to convert the pandas columns into numpy arrays. The function also store the array in a dictionnary to facilitate the accessibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f083935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_numpy(df):\n",
    "    arrays = {}\n",
    "    for col in df.columns:\n",
    "        arrays[col] = df[col].to_numpy()\n",
    "    return arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd7e3f",
   "metadata": {},
   "source": [
    "Let's have a look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas_to_numpy(df_data)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd93a3",
   "metadata": {},
   "source": [
    "We will now create the Neo object according to the structure explained above:\\\n",
    "We start with formating the signals in AnalogSignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "821b3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo.core import AnalogSignal,Segment,Block\n",
    "import quantities as pq\n",
    "\n",
    "sig0 = AnalogSignal(data['Signal 1'], units='V', sampling_rate=1000*pq.Hz, t_start=0*pq.s)\n",
    "sig1 = AnalogSignal(data['Signal 2'], units='V', sampling_rate=1000*pq.Hz, t_start=0*pq.s)\n",
    "sig2 = AnalogSignal(data['Signal 3'], units='V', sampling_rate=1000*pq.Hz, t_start=0*pq.s)\n",
    "sig3 = AnalogSignal(data['Signal 4'], units='V', sampling_rate=1000*pq.Hz, t_start=0*pq.s)\n",
    "sig4 = AnalogSignal(data['Signal 5'], units='V', sampling_rate=1000*pq.Hz, t_start=0*pq.s)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a08d1",
   "metadata": {},
   "source": [
    "Now, we create the segment regrouping all signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "591a8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = Segment(index=5)\n",
    "seg.analogsignals.append(sig0)\n",
    "seg.analogsignals.append(sig1)\n",
    "seg.analogsignals.append(sig2)\n",
    "seg.analogsignals.append(sig3)\n",
    "seg.analogsignals.append(sig4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33e4c1",
   "metadata": {},
   "source": [
    "Let's have a look:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc45ce6",
   "metadata": {},
   "source": [
    "And then, we create the block containing 1 segment and 5 signals(analogsignals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk = Block()\n",
    "for ind in range(3):\n",
    "        blk.segments.append(seg)\n",
    "blk.annotate(description = \"data for minischool\")\n",
    "blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350304e",
   "metadata": {},
   "source": [
    "To go further, you can check this example: https://neo.readthedocs.io/en/latest/share_data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
